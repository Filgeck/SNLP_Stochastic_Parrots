{"instance_id": "astropy__astropy-12907", "model_patch": "--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -242,7 +242,7 @@\n         cright = _coord_matrix(right, 'right', noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0]:, -right.shape[1]:] = right\n \n     return np.hstack([cleft, cright])", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "astropy__astropy-14182", "model_patch": "```patch\n--- a/astropy/io/ascii/core.py\n+++ b/astropy/io/ascii/core.py\n@@ -1789,6 +1789,7 @@\n     \"fill_values\",\n     \"fill_include_names\",\n     \"fill_exclude_names\",\n+    \"header_rows\",  # Added for RST writer\n )\n \n \n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -1,7 +1,7 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n \"\"\"An extensible ASCII table reader and writer.\n \n-rst.py:\n+rst.py: Read and write tables in reStructuredText simple table format.\n \n :Copyright: Smithsonian Astrophysical Observatory (2011)\n :Author: Tom Aldcroft (aldcroft@head.cfa.harvard.edu)\n@@ -10,7 +10,7 @@\n import re\n \n from . import core, fixedwidth\n-from .fixedwidth import FixedWidthHeader, FixedWidthData\n+from .fixedwidth import FixedWidthHeader\n \n __doctest_skip__ = [\"*\"]\n \n@@ -104,13 +104,77 @@\n     _io_registry_format_aliases = [\"rst\"]\n     _description = \"reStructuredText simple table format\"\n \n-    header_class = RSTHeader\n-    data_class = FixedWidthData\n+    header_class = fixedwidth.FixedWidthHeader\n+    data_class = fixedwidth.FixedWidthData\n \n-    def __init__(self):\n-        super().__init__()\n+    def __init__(self, header_rows=None, **kwargs):\n+        super().__init__(**kwargs)\n         self.header.splitter_class = fixedwidth.FixedWidthSplitter\n         self.data.splitter_class = fixedwidth.FixedWidthSplitter\n+        # RST requires column names, so don't allow setting to None. This is\n+        # checked upstream in ui.py, but keep this failsafe here.\n+        if self.header.start_line is None:\n+            self.header.start_line = 0\n+        self.header_rows = header_rows\n+\n+    def _get_col_attribute(self, col, attr_name):\n+        \"\"\"Helper to get column attribute string, handling units etc.\"\"\"\n+        if attr_name == \"name\":\n+            return col.info.name\n+        elif attr_name == \"unit\":\n+            unit = getattr(col.info, \"unit\", None)\n+            # Use format 'generic' to get simple string like 'ct', 'm / s'\n+            unit_str = \"\"\n+            if unit is not None:\n+                try:\n+                    # Try formatting, handle potential errors if unit is weird\n+                    unit_str = unit.to_string(format=\"generic\")\n+                except Exception:\n+                    unit_str = str(unit)  # Fallback to simple string representation\n+            # Return '---' if unit string is empty after formatting/conversion\n+            return unit_str if unit_str else \"---\"\n+        elif attr_name == \"description\":\n+            return getattr(col.info, \"description\", \"\") or \"\"  # Ensure string\n+        # Add more attributes if needed later (dtype?)\n+        else:\n+            # For unknown attributes, return empty string.\n+            return \"\"\n \n     def write(self, table):\n-        \"\"\"Write ``table`` as a simple RST table.\"\"\"\n+        \"\"\"Write ``table`` as a simple RST table.\n+\n+        Parameters\n+        ----------\n+        table : `~astropy.table.Table`\n+            Input table data.\n+\n+        Returns\n+        -------\n+        lines : list\n+            List of strings corresponding to ASCII table\n+\n+        \"\"\"\n+        # Overrides BaseReader.write to control the formatting and add header rows\n+        # Perform initial setup from BaseReader.write\n+        core._apply_base_reader_settings(self, table)\n+\n+        # Get string representations of data columns using internal methods\n+        # that also apply formatting and fillna replacement.\n+        list_str_vals = self.data.str_vals()\n+\n+        header_rows_to_write = self.header_rows\n+        if header_rows_to_write is None:\n+            header_rows_to_write = [\"name\"]\n+        elif not isinstance(header_rows_to_write, list):\n+            raise TypeError(\n+                \"'header_rows' must be a list of strings (e.g., ['name', 'unit'])\"\n+            )\n+\n+        # Calculate widths needed for columns from header and data\n+        widths = []\n+        header_vals = {attr: [] for attr in header_rows_to_write}\n+        for i, col in enumerate(self.cols):\n+            max_width = 0\n+            for attr in header_rows_to_write:\n+                hval = self._get_col_attribute(col, attr)\n+                header_vals[attr].append(hval)\n+                max_width = max(max_width, len(hval))\n+\n+            if list_str_vals:\n+                col_str_vals = list_str_vals[i]\n+                if col_str_vals:\n+                    max_width = max(max_width, max(len(x) for x in col_str_vals))\n+\n+            # Ensure minimum width of 1, even if all values are empty strings\n+            widths.append(max(1, max_width))\n+\n+        # Generate output lines\n+        lines = []\n+        self.header.write_comments(lines, table.meta)\n+\n+        def get_separator(char=\"=\"):\n+            return \" \".join([char * width for width in widths])\n+\n+        # Top separator\n+        lines.append(get_separator(\"=\"))\n+\n+        # Header row(s)\n+        for attr in header_rows_to_write:\n+            vals = header_vals[attr]\n+            header_line = \" \".join(val.ljust(width) for val, width in zip(vals, widths))\n+            lines.append(header_line)\n+\n+        # Separator after *all* header rows\n+        lines.append(get_separator(\"=\"))\n+\n+        # Data rows\n+        if list_str_vals:\n+            for row_vals in zip(*list_str_vals):\n+                data_line = \" \".join(val.ljust(width) for val, width in zip(row_vals, widths))\n+                lines.append(data_line)\n+\n+            # Bottom separator (only if data was written)\n+            lines.append(get_separator(\"=\"))\n+        # Add bottom separator even if no data, provided header was written\n+        elif header_rows_to_write:\n+            lines.append", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "astropy__astropy-14365", "model_patch": "--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -63,7 +63,8 @@\n     ValueError: Unrecognized QDP line...\n     \"\"\"\n     _decimal_re = r\"[+-]?(\\d+(\\.\\d*)?|\\.\\d+)([eE][+-]?\\d+)?\"\n-    _command_re = r\"READ [TS]ERR(\\s+[0-9]+)+\"\n+    # Make READ and TERR/SERR case-insensitive\n+    _command_re = r\"(?i:READ)\\s+(?i:[TS]ERR)(\\s+[0-9]+)+\"\n \n     sep = delimiter\n     if delimiter is None:\n--- a/astropy/io/ascii/tests/test_qdp.py\n+++ b/astropy/io/ascii/tests/test_qdp.py\n@@ -1,7 +1,8 @@\n # Licensed under a 3-clause BSD style license - see LICENSE.rst\n \n import os\n-\n+import pytest\n+import numpy as np\n from numpy.testing import assert_allclose\n \n from astropy.table import Table\n@@ -111,3 +112,53 @@\n         with pytest.raises(ValueError, match=\"Inconsistent number of columns\"):\n             Table.read(qdp_file, format=\"ascii.qdp\")\n         os.remove(self.data_dir / \"test_multiple_different_ncol.qdp\")\n+\n+    def test_read_lowercase_commands(self):\n+        \"\"\"Test reading QDP with lowercase commands.\"\"\"\n+        qdp_file = \"\"\"\n+! Test lowercase commands\n+read serr 1 2\n+1 0.5 1 0.5\n+2 1.0 2 1.0\n+\"\"\"\n+        t = Table.read(qdp_file, format=\"ascii.qdp\", names=[\"a\", \"b\"])\n+        assert t.colnames == [\"a\", \"a_err\", \"b\", \"b_err\"]\n+        assert len(t) == 2\n+        assert_allclose(t[\"a\"], [1, 2])\n+        assert_allclose(t[\"a_err\"], [0.5, 1.0])\n+        assert_allclose(t[\"b\"], [1, 2])\n+        assert_allclose(t[\"b_err\"], [0.5, 1.0])\n+\n+    def test_read_mixedcase_commands(self):\n+        \"\"\"Test reading QDP with mixed case commands.\"\"\"\n+        qdp_file = \"\"\"\n+! Test mixed case commands\n+ReAd TeRr 1\n+Read SeRr 2\n+1 0.1 0.2 3 0.3\n+2 0.4 0.5 4 0.6\n+\"\"\"\n+        t = Table.read(qdp_file, format=\"ascii.qdp\", names=[\"a\", \"b\"])\n+        assert t.colnames == [\"a\", \"a_perr\", \"a_nerr\", \"b\", \"b_err\"]\n+        assert len(t) == 2\n+        assert_allclose(t[\"a\"], [1, 2])\n+        assert_allclose(t[\"a_perr\"], [0.1, 0.4])\n+        assert_allclose(t[\"a_nerr\"], [0.2, 0.5])\n+        assert_allclose(t[\"b\"], [3, 4])\n+        assert_allclose(t[\"b_err\"], [0.3, 0.6])\n+\n+    def test_read_uppercase_commands(self):\n+        \"\"\"Test reading QDP with standard uppercase commands.\"\"\"\n+        qdp_file = \"\"\"\n+! Test uppercase commands\n+READ SERR 1 2\n+1 0.5 1 0.5\n+2 1.0 2 1.0\n+\"\"\"\n+        t = Table.read(qdp_file, format=\"ascii.qdp\", names=[\"a\", \"b\"])\n+        assert t.colnames == [\"a\", \"a_err\", \"b\", \"b_err\"]\n+        assert len(t) == 2\n+        assert_allclose(t[\"a\"], [1, 2])\n+        assert_allclose(t[\"a_err\"], [0.5, 1.0])\n+        assert_allclose(t[\"b\"], [1, 2])\n+        assert_allclose(t[\"b_err\"], [0.5, 1.0])", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "astropy__astropy-14995", "model_patch": "--- a/astropy/nddata/mixins/ndarithmetic.py\n+++ b/astropy/nddata/mixins/ndarithmetic.py\n@@ -485,7 +485,10 @@\n     def _arithmetic_mask(self, operation, operand, handle_mask, axis=None, **kwds):\n         \"\"\"\n         Calculate the resulting mask.\n-\n+ \n+        .. note::\n+            This method is only called when ``handle_mask`` is a callable.\n+            Other cases like ``None`` or ``'first_found'`` are handled by the caller.\n         This is implemented as the piecewise ``or`` operation if both have a\n         mask.\n \n@@ -513,18 +516,26 @@\n             If neither had a mask ``None`` is returned. Otherwise\n             ``handle_mask`` must create (and copy) the returned mask.\n         \"\"\"\n-        # If only one mask is present we need not bother about any type checks\n+        self_mask = self.mask\n+        # Handle collapse operations where operand is None\n+        operand_mask = operand.mask if operand is not None else None\n+ \n+        # If only one mask is present, return a copy of it.\n+        # The handle_mask callable is only applied if *both* masks exist.\n         if (\n-            self.mask is None and operand is not None and operand.mask is None\n-        ) or handle_mask is None:\n+            self_mask is None and operand_mask is not None\n+        ):  # Only operand has mask\n+            return deepcopy(operand_mask)\n+        elif (\n+            self_mask is not None and operand_mask is None\n+        ):  # Only self has mask\n+            return deepcopy(self_mask)\n+        elif self_mask is None and operand_mask is None:\n+            # This case happens for instance during collapse operations like sum()\n+            # if the original object had no mask.\n             return None\n-        elif self.mask is None and operand is not None:\n-            # Make a copy so there is no reference in the result.\n-            return deepcopy(operand.mask)\n-        elif operand is None:\n-            return deepcopy(self.mask)\n-        else:\n-            # Now lets calculate the resulting mask (operation enforces copy)\n-            return handle_mask(self.mask, operand.mask, **kwds)\n+        else:  # Both self_mask and operand_mask exist\n+            # Now it's safe to calculate the resulting mask using the callable\n+            return handle_mask(self_mask, operand_mask, **kwds)\n \n     def _arithmetic_wcs(self, operation, operand, compare_wcs, **kwds):\n         \"\"\"", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "astropy__astropy-6938", "model_patch": "--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -1261,7 +1261,7 @@\n \n         # Replace exponent separator in floating point numbers\n         if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+            output_field[:] = output_field.replace(encode_ascii('E'), encode_ascii('D'))\n \n \n def _get_recarray_field(array, key):", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "astropy__astropy-7746", "model_patch": "--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -1219,6 +1219,13 @@\n \n             xy = np.hstack([x.reshape((x.size, 1)) for x in axes])\n \n+            # Short-circuit if the input arrays are empty\n+            if xy.shape[0] == 0:\n+                # Determine expected number of output axes\n+                nout = 2 if (ra_dec_order and sky == 'output') else self.naxis\n+                # Return list of empty arrays with the broadcast shape\n+                return [np.zeros(axes[0].shape, dtype=float)] * nout\n+\n             if ra_dec_order and sky == 'input':\n                 xy = self._denormalize_sky(xy)\n             output = func(xy, origin)\n@@ -1236,6 +1243,14 @@\n                 raise ValueError(\n                     \"When providing two arguments, the array must be \"\n                     \"of shape (N, {0})\".format(self.naxis))\n+\n+            # Short-circuit if the input array is empty\n+            if xy.shape[0] == 0:\n+                # Determine expected number of output axes\n+                nout = 2 if (ra_dec_order and sky == 'output') else self.naxis\n+                # Return an empty array with shape (0, nout)\n+                return np.zeros((0, nout), dtype=float)\n+\n             if ra_dec_order and sky == 'input':\n                 xy = self._denormalize_sky(xy)\n             result = func(xy, origin)", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-10914", "model_patch": "--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -304,7 +304,7 @@\n \n # The numeric mode to set newly-uploaded files to. The value should be a mode\n # you'd pass directly to os.chmod; see https://docs.python.org/library/os.html#files-and-directories.\n-FILE_UPLOAD_PERMISSIONS = None\n+FILE_UPLOAD_PERMISSIONS = 0o644\n \n # The numeric mode to assign to newly-created directories, when uploading files.\n # The value should be a mode as you'd pass to os.chmod;", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-10924", "model_patch": "--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1661,10 +1661,15 @@\n class FilePathField(Field):\n     description = _(\"File path\")\n \n-    def __init__(self, verbose_name=None, name=None, path='', match=None,\n+    def __init__(self, verbose_name=None, name=None, path='', *, match=None,\n                   recursive=False, allow_files=True, allow_folders=False, **kwargs):\n-        self.path, self.match, self.recursive = path, match, recursive\n+        if not callable(path) and not isinstance(path, str):\n+            raise TypeError(\n+                \"'path' must be a string or callable accepting no arguments.\"\n+            )\n+        self.path = path\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n+        self.match, self.recursive = match, recursive\n         kwargs.setdefault('max_length', 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n@@ -1689,8 +1694,12 @@\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n+        # Handle path default. path='' is the default.\n         if self.path != '':\n-            kwargs['path'] = self.path\n+            # Different from default path, must preserve.\n+            # path can be a callable, deconstructor handles it.\n+            kwargs['path'] = self.path\n+        # Handle other defaults.\n         if self.match is not None:\n             kwargs['match'] = self.match\n         if self.recursive is not False:\n@@ -1711,8 +1720,9 @@\n         return str(value)\n \n     def formfield(self, **kwargs):\n+        path = self.path() if callable(self.path) else self.path\n         return super().formfield(**{\n-            'path': self.path,\n+            'path': path,\n             'match': self.match,\n             'recursive': self.recursive,\n             'form_class': forms.FilePathField,\n--- a/tests/model_fields/test_filepathfield.py\n+++ b/tests/model_fields/test_filepathfield.py\n@@ -1,10 +1,15 @@\n import os\n+from unittest import mock\n \n from django import forms\n from django.core import checks\n from django.db import models\n-from django.test import SimpleTestCase\n+from django.test import SimpleTestCase, override_settings\n \n TEST_FILES_ROOT = os.path.join(os.path.dirname(__file__), 'filepathfield_test_files')\n TEST_FILES_PATH = os.path.join(TEST_FILES_ROOT, 'test_files')\n+TEST_FILES_PATH_CALLABLE = lambda: TEST_FILES_PATH\n+\n \n class FilePathFieldTests(SimpleTestCase):\n \n@@ -49,3 +54,66 @@\n         field = models.FilePathField(allow_files=False, allow_folders=False)\n         errors = field.check()\n         self.assertEqual(errors[0].id, 'fields.E140')\n+\n+    def test_path_callable(self):\n+        \"\"\"\n+        FilePathField path argument can be a callable.\n+        \"\"\"\n+        field = models.FilePathField(path=TEST_FILES_PATH_CALLABLE)\n+        self.assertTrue(callable(field.path))\n+        # Ensure formfield evaluates the callable\n+        form_field = field.formfield()\n+        self.assertIsInstance(form_field, forms.FilePathField)\n+        self.assertEqual(form_field.path, TEST_FILES_PATH)\n+\n+    def test_path_callable_check(self):\n+        \"\"\"\n+        Check that FilePathField doesn't raise errors with a callable path.\n+        \"\"\"\n+        class MyModel(models.Model):\n+            file = models.FilePathField(path=TEST_FILES_PATH_CALLABLE)\n+\n+        field = MyModel._meta.get_field('file')\n+        errors = field.check()\n+        self.assertEqual(errors, [])\n+\n+    def test_path_non_string_or_callable_raises_error(self):\n+        \"\"\"\n+        FilePathField path must be a string or callable.\n+        \"\"\"\n+        msg = \"'path' must be a string or callable accepting no arguments.\"\n+        with self.assertRaisesMessage(TypeError, msg):\n+            models.FilePathField(path=123)\n+        with self.assertRaisesMessage(TypeError, msg):\n+            models.FilePathField(path=['a', 'b'])\n+\n+    def test_deconstruct_callable_path(self):\n+        \"\"\"\n+        Deconstruct should preserve the callable path.\n+        \"\"\"\n+        field = models.FilePathField(path=TEST_FILES_PATH_CALLABLE)\n+        name, path, args, kwargs = field.deconstruct()\n+        self.assertIn('path', kwargs)\n+        self.assertEqual(kwargs['path'], TEST_FILES_PATH_CALLABLE)\n+\n+    @override_settings(MEDIA_ROOT=TEST_FILES_ROOT)\n+    def test_formfield_callable_path_choices(self):\n+        \"\"\"\n+        Choices generated by the formfield should use the callable path.\n+        \"\"\"\n+        # Create some dummy files/dirs\n+        os.makedirs(TEST_FILES_PATH, exist_ok=True)\n+        with open(os.path.join(TEST_FILES_PATH, 'test_file1.txt'), 'w') as f:\n+            f.write('test')\n+        with open(os.path.join(TEST_FILES_PATH, 'test_file2.log'), 'w') as f:\n+            f.write('test')\n+        os.makedirs(os.path.join(TEST_FILES_PATH, 'test_dir'), exist_ok=True)\n+\n+        field = models.FilePathField(path=TEST_FILES_PATH_CALLABLE, allow_folders=True)\n+        form_field = field.formfield()\n+        expected_choices = [\n+            ('', '---------'),\n+            (os.path.join(TEST_FILES_PATH, 'test_file1.txt'), 'test_file1.txt'),\n+            (os.path.join(TEST_FILES_PATH, 'test_file2.log'), 'test_file2.log'),\n+            (os.path.join(TEST_FILES_PATH, 'test_dir'), 'test_dir'),\n+        ]\n+        self.assertCountEqual(form_field.choices, expected_choices)\n--- a/tests/migrations/test_writer.py\n+++ b/tests/migrations/test_writer.py\n@@ -1,9 +1,10 @@\n import datetime\n import os\n import re\n+from unittest import skipUnless\n \n from django.conf import settings\n-from django.core.files.storage import FileSystemStorage\n+from django.core.files.storage import FileSystemStorage, Storage\n from django.db import models, migrations\n from django.db.migrations.writer import MigrationWriter, OperationWriter\n from django.db.models.fields import NOT_PROVIDED\n@@ -15,6 +16,13 @@\n from django.test import SimpleTestCase, override_settings\n from django.utils.functional import SimpleLazyObject\n from django.utils.timezone import get_default_timezone, utc\n+\n+# Define a callable path function at the module level so it can be imported\n+# by the generated migration string.\n+TEST_MIGRATIONS_DIR = os.path.join(os.path.dirname(__file__), 'migrations_test_apps')\n+\n+def writer_callable_path_func():\n+    return os.path.join(TEST_MIGRATIONS_DIR, 'test_writer_path')\n \n \n class SettingsReferenceSerializerTests(SimpleTestCase):\n@@ -395,3 +403,26 @@\n         self.assertEqual(migration.dependencies, [])\n         self.assertEqual(migration.operations, [])\n         self.assertFalse(migration.initial)\n+\n+\n+class WriterCallablePathTests(SimpleTestCase):\n+\n+    def test_serialize_filepathfield_with_callable_path(self):\n+        \"\"\"\n+        Test serialization of FilePathField with a callable path.\n+        \"\"\"\n+        field = models.FilePathField(path=writer_callable_path_func)\n+        field.set_attributes_from_name(\"callable_path_field\")\n+        serialized_string, imports = MigrationWriter.serialize(field)\n+\n+        # Check imports: the module containing the callable should be imported\n+        self.assertIn('import tests.migrations.test_writer', imports)\n+\n+        # Check serialized string: it should reference the callable\n+        expected_path_ref = 'tests.migrations.test_writer.writer_callable_path_func'\n+        self.assertIn(f\"path={expected_path_ref}\", serialized_string)\n+        self.assertIn(\"models.FilePathField(\", serialized_string)\n+\n+    # A full integration test for makemigrations could be added here or in\n+    # tests/migrations/test_commands.py, but the unit test above covers the\n+    # core serialization logic.", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11001", "model_patch": "--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -32,7 +32,7 @@\n         self.select = None\n         self.annotation_col_map = None\n         self.klass_info = None\n-        self.ordering_parts = re.compile(r'(.*)\\s(ASC|DESC)(.*)')\n+        self.ordering_parts = re.compile(r'(.*)\\s(ASC|DESC)(.*)', re.DOTALL)\n         self._meta_ordering = None\n \n     def setup_query(self):", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11019", "model_patch": "```patch\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -3,11 +3,12 @@\n \"\"\"\n \n import copy\n+from collections import defaultdict\n import datetime\n import re\n import warnings\n from itertools import chain\n- \n+\n from django.conf import settings\n from django.forms.utils import to_current_timezone\n from django.templatetags.static import static\n@@ -45,36 +46,72 @@\n @html_safe\n class Media:\n     def __init__(self, media=None, css=None, js=None):\n+        # If media is provided, use its _css_lists and _js_lists.\n         if media is not None:\n-            css = getattr(media, 'css', {})\n-            js = getattr(media, 'js', [])\n-        else:\n-            if css is None:\n-                css = {}\n-            if js is None:\n-                js = []\n-        self._css_lists = [css]\n-        self._js_lists = [js]\n+            self._css_lists = getattr(media, '_css_lists', [])\n+            self._js_lists = getattr(media, '_js_lists', [])\n+            # Add css/js arguments to the lists.\n+            if css:\n+                self._css_lists.append(css)\n+            if js:\n+                self._js_lists.append(js)\n+            # If css/js are None, initialize with empty lists.\n+            if css is None and not hasattr(media, '_css_lists'):\n+                self._css_lists.append({})\n+            if js is None and not hasattr(media, '_js_lists'):\n+                self._js_lists.", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11039", "model_patch": "--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -56,7 +56,7 @@\n         targets = [(app_label, migration.name)]\n \n         # Show begin/end around output only for atomic migrations\n-        self.output_transaction = migration.atomic\n+        self.output_transaction = migration.atomic and connection.features.can_rollback_ddl\n \n         # Make a plan that represents just the requested migrations and show SQL\n         # for it", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11049", "model_patch": "--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1587,7 +1587,7 @@\n     empty_strings_allowed = False\n     default_error_messages = {\n         'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"[DD] [HH:[MM:]]ss[.uuuuuu] format.\")\n+                     \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\")\n     }\n     description = _(\"Duration\")\n \n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -472,6 +472,12 @@\n         'overflow': _('The number of days must be between {min_days} and {max_days}.')\n     }\n \n+    def __init__(self, **kwargs):\n+        help_text = _('Enter a duration in the format [DD] [[HH:]MM:]ss[.uuuuuu].')\n+        kwargs.setdefault('help_text', help_text)\n+        super().__init__(**kwargs)\n+\n+\n     def prepare_value(self, value):\n         if isinstance(value, datetime.timedelta):\n             return duration_string(value)", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11099", "model_patch": "--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,7 @@\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -18,7 +18,7 @@\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11133", "model_patch": "--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -232,6 +232,8 @@\n         # - when self._charset != 'utf-8' it re-encodes the content\n         if isinstance(value, bytes):\n             return bytes(value)\n+        if isinstance(value, memoryview):\n+            return bytes(value)\n         if isinstance(value, str):\n             return bytes(value.encode(self.charset))\n         # Handle non-string types.", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11179", "model_patch": "--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,7 +277,8 @@\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n-                return count, {model._meta.label: count}\n+                setattr(instance, model._meta.pk.attname, None)\n+                return count, {model._meta.label: count}\n\n         with transaction.atomic(using=self.using, savepoint=False):\n             # send pre_delete signals", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11283", "model_patch": "--- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n+++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n@@ -33,9 +33,9 @@\n                 for action in opts.default_permissions:\n                     codename = '%s_%s' % (action, opts.model_name)\n                     name = 'Can %s %s' % (action, opts.verbose_name_raw)\n-                    defaults = {'name': name, 'content_type': concrete_ctype}\n                     Permission.objects.using(alias).get_or_create(\n                         codename=codename,\n-                        defaults=defaults,\n+                        content_type=concrete_ctype,\n+                        defaults={'name': name},\n                     )\n                 # Remove the ContentType of the proxy model.\n                 proxy_ctype.delete()", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11422", "model_patch": "--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -244,6 +244,11 @@\n         \"\"\"\n         yield from iter_all_python_module_files()\n         yield from self.extra_files\n+        # Add the main script file (e.g. manage.py).\n+        main_script = Path(sys.argv[0])\n+        if main_script.exists():\n+            # Use resolve() to follow symlinks.\n+            yield main_script.resolve().absolute()\n         if include_globs:\n             for directory, patterns in self.directory_globs.items():\n                 for pattern in patterns:", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11564", "model_patch": "--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -4,10 +4,11 @@\n import os\n import re\n import time\n-from datetime import datetime\n-from urllib.parse import urljoin\n+from datetime import datetime, timezone\n+from urllib.parse import urljoin, urlsplit\n \n from django.conf import settings\n+from django.urls import get_script_prefix\n from django.core.exceptions import ImproperlyConfigured, SuspiciousFileOperation\n from django.core.files import File\n from django.core.signals import setting_changed\n@@ -132,7 +133,21 @@\n         if self.base_url is None:\n             raise ValueError(\"This file is not accessible via a URL.\")\n         url = filepath_to_uri(name)\n-        return urljoin(self.base_url, url)\n+\n+        # Handle SCRIPT_NAME prefix for root-relative base URLs.\n+        base_url = self.base_url\n+        base_url_parts = urlsplit(base_url)\n+\n+        # Check if the base_url is a path (no scheme or netloc) and starts\n+        # with '/'. This identifies root-relative paths like '/static/' but not\n+        # '//example.com/static/' or 'http://example.com/static/'.\n+        if not base_url_parts.scheme and not base_url_parts.netloc and base_url.startswith('/'):\n+            prefix = get_script_prefix().rstrip('/')\n+            # Prepend prefix if it exists and base_url doesn't already start\n+            # with it (to avoid double-prefixing).\n+            if prefix and not base_url.startswith(prefix + '/'):\n+                base_url = prefix + base_url\n+        return urljoin(base_url, url)\n \n     def _save(self, name, content):\n         full_path = self.path(name)\n@@ -221,7 +236,7 @@\n             return name\n \n     def get_accessed_time(self, name):\n-        return datetime.fromtimestamp(os.path.getatime(self.path(name)))\n+        return datetime.fromtimestamp(os.path.getatime(self.path(name)), tz=timezone.utc)\n \n     def get_created_time(self, name):\n         \"\"\"\n@@ -230,10 +245,10 @@\n         Return a datetime that represents the creation time (platform\n         dependent).\n         \"\"\"\n-        return datetime.fromtimestamp(os.path.getctime(self.path(name)))\n+        return datetime.fromtimestamp(os.path.getctime(self.path(name)), tz=timezone.utc)\n \n     def get_modified_time(self, name):\n-        return datetime.fromtimestamp(os.path.getmtime(self.path(name)))\n+        return datetime.fromtimestamp(os.path.getmtime(self.path(name)), tz=timezone.utc)\n \n \n def get_storage_class(import_path=None):", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11583", "model_patch": "--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -140,12 +140,17 @@\n             continue\n         path = Path(filename)\n         try:\n-            resolved_path = path.resolve(strict=True).absolute()\n+            resolved_path = path.resolve().absolute()\n         except FileNotFoundError:\n             # The module could have been removed, don't fail loudly if this\n             # is the case.\n             continue\n+        except ValueError as e:\n+            # Certain paths can raise a ValueError, e.g. accessing properties of\n+            # a non-existent file on CIFS shares.\n+            if 'embedded null byte' in str(e):\n+                logger.warning('Skipping path %s (%r). It will not be watched for changes.', path, e)\n+                continue\n+            raise\n         results.add(resolved_path)\n     return frozenset(results)", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11620", "model_patch": "--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -17,6 +17,7 @@\n from django.core.checks import Error, Warning\n from django.core.checks.urls import check_resolver\n from django.core.exceptions import ImproperlyConfigured, ViewDoesNotExist\n+from django.http import Http404\n from django.utils.datastructures import MultiValueDict\n from django.utils.functional import cached_property\n from django.utils.http import RFC3986_SUBDELIMS, escape_leading_slashes\n@@ -259,7 +260,8 @@\n                 converter = self.converters[key]\n                 try:\n                     kwargs[key] = converter.to_python(value)\n-                except ValueError:\n+                # Treat Http404 raised during conversion as a resolver mismatch.\n+                except (ValueError, Http404):\n                     return None\n             return path[match.end():], (), kwargs\n         return None\n--- /dev/null\n+++ b/tests/urlpatterns/path_converter_urls_404.py\n@@ -0,0 +1,28 @@\n+from django.http import Http404\n+from django.urls import path, register_converter\n+\n+from . import views\n+\n+\n+class RaiserConverter:\n+    regex = '[0-9]+'\n+\n+    def to_python(self, value):\n+        val = int(value)\n+        if val == 404:\n+            # This Http404 should cause the resolver to skip this path.\n+            raise Http404('Value 404 not allowed here, triggering Http404.')\n+        elif val == 500:\n+            # This ValueError should cause the resolver to skip this path.\n+            raise ValueError('Value 500 not allowed here, triggering ValueError.')\n+        return val\n+\n+    def to_url(self, value):\n+        return str(value)\n+\n+\n+register_converter(RaiserConverter, 'raiser')\n+\n+urlpatterns = [\n+    path('raiser/<raiser:val>/', views.empty_view, name='raiser'),\n+]\n--- a/tests/urlpatterns/tests.py\n+++ b/tests/urlpatterns/tests.py\n@@ -1,10 +1,12 @@\n import sys\n+from unittest import mock\n \n from django.conf import settings\n from django.core.checks import Error, Warning\n from django.core.exceptions import ImproperlyConfigured\n from django.http import HttpResponse\n from django.test import RequestFactory, SimpleTestCase, override_settings\n+from django.template.response import SimpleTemplateResponse\n from django.urls import (\n     NoReverseMatch, Resolver404, get_ns_resolver, get_resolver, include, path,\n     re_path, resolve, reverse, set_urlconf,\n@@ -695,3 +697,81 @@\n         msg = \"Reverse for 'no_parameters' not found. 'no_parameters' is not a valid view function or pattern name.\"\n         with self.assertRaisesMessage(NoReverseMatch, msg):\n             reverse('no_parameters')\n+\n+\n+@override_settings(ROOT_URLCONF='urlpatterns.path_converter_urls_404')\n+class PathConverterRaises404Tests(SimpleTestCase):\n+\n+    @override_settings(DEBUG=True)\n+    def test_converter_http404_debug(self):\n+        \"\"\"\n+        Http404 raised in converter's to_python() should produce technical 404\n+        in DEBUG mode, not a 500.\n+        \"\"\"\n+        response = self.client.get('/raiser/404/')\n+        # The URL resolver should skip the pattern and eventually raise Resolver404,\n+        # leading to the standard 404 handling.\n+        self.assertEqual(response.status_code, 404)\n+        self.assertContains(response, 'Page not found', status_code=404)\n+        # Check for a unique string from the technical 404 template.\n+        self.assertContains(response, 'Using the URLconf defined in', status_code=404)\n+        self.assertNotContains(response, 'A server error occurred')\n+        # Exception message shouldn't leak.\n+        self.assertNotContains(response, 'Value 404 not allowed here')\n+\n+    @override_settings(\n+        DEBUG=False,\n+        TEMPLATES=[{\n+            'BACKEND': 'django.template.backends.django.DjangoTemplates',\n+            'DIRS': [],\n+        }],\n+    )\n+    @mock.patch('django.views.defaults.page_not_found', return_value=SimpleTemplateResponse('404.html'))\n+    def test_converter_http404_no_debug(self, mocked_page_not_found):\n+        \"\"\"\n+        Http404 raised in converter's to_python() should produce standard 404\n+        if DEBUG=False.\n+        \"\"\"\n+        # This requires a 404 handler template to be configured for content check,\n+        # but the status code check is the main point.\n+        response = self.client.get('/raiser/404/')\n+        self.assertEqual(response.status_code, 404)\n+        self.assertTrue(mocked_page_not_found.called)\n+\n+    @override_settings(DEBUG=True)\n+    def test_converter_valueerror_debug(self):\n+        \"\"\"\n+        ValueError raised in converter's to_python() should also result in a\n+        technical 404 (as the pattern is skipped).\n+        \"\"\"\n+        response = self.client.get('/raiser/500/')\n+        self.assertEqual(response.status_code, 404)\n+        self.assertContains(response, 'Page not found', status_code=404)\n+        self.assertContains(response, 'Using the URLconf defined in', status_code=404)\n+        self.assertNotContains(response, 'A server error occurred')\n+        # Exception message shouldn't leak.\n+        self.assertNotContains(response, 'Value 500 not allowed here')\n+\n+    def test_converter_success(self):\n+        \"\"\"Ensure valid values are passed through the converter.\"\"\"\n+        response = self.client.get('/raiser/123/')\n+        self.assertEqual(response.status_code, 200)\n+        self.assertContains(response, 'OK')\n+\n+    def test_resolver_raises_resolver404_on_converter_http404(self):\n+        \"\"\"\n+        URL resolver raises Resolver404 when the converter raises Http404.\n+        \"\"\"\n+        resolver = get_resolver()\n+        msg = {'path': 'raiser/404/'}\n+        with self.assertRaisesMessage(Resolver404, str(msg)):\n+            resolver.resolve('/raiser/404/')\n+\n+    def test_resolver_raises_resolver404_on_converter_valueerror(self):\n+        \"\"\"\n+        URL resolver raises Resolver404 when the converter raises ValueError\n+        (existing behavior).\n+        \"\"\"\n+        resolver = get_resolver()\n+        msg = {'path': 'raiser/500/'}\n+        with self.assertRaisesMessage(Resolver404, str(msg)):\n+            resolver.resolve('/raiser/500/')\n--- /dev/null\n+++ b/tests/urlpatterns/views.py\n@@ -0,0 +1,5 @@\n+from django.http import HttpResponse\n+\n+\n+def empty_view(request, *args, **kwargs):\n+    return HttpResponse('OK')", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11630", "model_patch": "--- a/django/core/checks/model_checks.py\n+++ b/django/core/checks/model_checks.py\n@@ -4,7 +4,7 @@\n from django.apps import apps\n from django.conf import settings\n from django.core.checks import Error, Tags, Warning, register\n-from django.db import models\n+from django.db import models, router\n from django.db.models.fields.related import RECURSIVE_RELATIONSHIP_CONSTANT\n from django.utils.module_loading import import_string\n from django.utils.version import get_docs_version\n@@ -46,19 +46,25 @@\n         )\n         errors.extend(model._check_ordering())\n         errors.extend(model._check_constraints())\n-    # Check for clashes between models referring to the same db_table\n-    db_table_models = defaultdict(list)\n+\n+    # Check for clashes between models referring to the same db_table *within the same database*.\n+    # Key: db_alias, Value: defaultdict(list) keyed by db_table\n+    db_table_models_per_db = defaultdict(lambda: defaultdict(list))\n     for model in apps.get_models():\n         if model._meta.managed and not model._meta.proxy:\n-            db_table_models[model._meta.db_table].append(model._meta.label)\n+            # Determine the database for this model using the router\n+            db_alias = router.db_for_write(model=model)\n+            db_table_models_per_db[db_alias][model._meta.db_table].append(model._meta.label)\n \n-    for db_table, model_labels in db_table_models.items():\n-        if len(model_labels) > 1:\n-            errors.append(\n-                Error(\n-                    \"db_table '%s' is used by multiple models: %s.\" % (\n-                        db_table, ', '.join(sorted(model_labels)),\n+    # Check for duplicates within each database alias\n+    for db_alias, db_table_models in db_table_models_per_db.items():\n+        for db_table, model_labels in db_table_models.items():\n+            if len(model_labels) > 1:\n+                errors.append(\n+                    Error(\n+                        \"db_table '%s' is used by multiple models routed to database '%s': %s.\" % (\n+                            db_table, db_alias, ', '.join(sorted(model_labels)),\n+                        ),\n+                        hint=(\n+                            \"Ensure that 'db_table' is unique among models \"\n+                            \"routed to the same database alias using your DATABASE_ROUTERS.\"\n+                        ),\n+                        id='models.E028',\n                     ),\n-                    id='models.E028',\n                 )\n-            )\n     return errors", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
{"instance_id": "django__django-11742", "model_patch": "--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -956,6 +956,7 @@\n         return [\n             *super().check(**kwargs),\n             *self._check_max_length_attribute(**kwargs),\n+            *self._check_max_length_choices(**kwargs),\n         ]\n \n     def _check_max_length_attribute(self, **kwargs):\n@@ -979,6 +980,32 @@\n         else:\n             return []\n \n+    def _check_max_length_choices(self, **kwargs):\n+        if not self.choices or self.max_length is None:\n+            return []\n+\n+        # Skip check if max_length isn't a positive integer. This is already\n+        # validated in _check_max_length_attribute().\n+        if (not isinstance(self.max_length, int) or isinstance(self.max_length, bool) or\n+                self.max_length <= 0):\n+            return []\n+\n+        max_choice_length = 0\n+        for value, _ in self.flatchoices:\n+            # The value is stored in the database so its length must fit\n+            # max_length. Convert to string to get length.\n+            choice_len = len(str(value))\n+            if choice_len > max_choice_length:\n+                max_choice_length = choice_len\n+\n+        if max_choice_length > self.max_length:\n+            return [\n+                checks.Warning(\n+                    f\"'max_length' is too small to fit the longest value in 'choices' ({max_choice_length} characters).\",\n+                    obj=self,\n+                    id='fields.W123',\n+                    hint=f'Increase max_length to at least {max_choice_length}.',\n+                )\n+            ]\n+        return []\n+\n     def cast_db_type(self, connection):\n         if self.max_length is None:\n             return connection.ops.cast_char_field_without_max_length", "model_name_or_path": "agent_a_gemini-2.5-pro-exp-03-25"}
