{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import polars as pl\n",
    "import lance\n",
    "\n",
    "from datasets import Dataset, load_dataset, IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373c235d6f40441d990cd2857a12773d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Batch: 0\n",
      "Processing Batch: 1\n",
      "Processing Batch: 2\n",
      "Processing Batch: 3\n",
      "Processing Batch: 4\n",
      "Processed Batches: 5\n",
      "\n",
      "Saving Dataset...\n",
      "Appending Batch: 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "str.join() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m base_dataset\n\u001b[32m     70\u001b[39m db_name = \u001b[33m\"\u001b[39m\u001b[33mstackexchange_base_db_lance\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m lance_dataset = \u001b[43mget_lance_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43msep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mget_lance_dataset\u001b[39m\u001b[34m(path, batch_limit, force_reload)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, c):\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAppending Batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     aux_path = \u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_batch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     aux_dataset = lance.dataset(aux_path)\n\u001b[32m     63\u001b[39m     base_dataset.insert(aux_dataset)\n",
      "\u001b[31mTypeError\u001b[39m: str.join() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "Q_SEP = \"Q:\\n\\n\"\n",
    "A_SEP = \"\\n\\nA:\\n\\n\"\n",
    "\n",
    "def process_qna(series: pl.Series):\n",
    "    return series.str.strip_prefix(Q_SEP).str.splitn(A_SEP, 3).struct.rename_fields([\"question\", \"answer\", \"_\"]).struct.unnest().drop(\"_\")\n",
    "\n",
    "\n",
    "\n",
    "STREAM_BATCH_BYTES = 2 ** 27 # ~128MB\n",
    "\n",
    "def process_batch(path: str, batch_iter, i: int):\n",
    "    print(f\"Processing Batch: {i}\")\n",
    "    batch = next(batch_iter)\n",
    "    pl_series = pl.Series(\"text\", batch[\"text\"])\n",
    "    pl_qna = process_qna(pl_series)\n",
    "    lance.write_dataset(pl_qna.to_arrow(), \"\".join([path, f\"_batch_{i}\"]) if i > 0 else path)\n",
    "\n",
    "def get_lance_dataset(path: str, batch_limit: int | None=None, force_reload=False):\n",
    "    \"path: str - make sure to make it an absolute path, or else it will redownload\"\n",
    "    if os.path.exists(path) and not force_reload:\n",
    "        base_dataset = lance.dataset(path)\n",
    "\n",
    "    else:\n",
    "        ds = load_dataset(\"bigscience-data/roots_code_stackexchange\", streaming=True)[\"train\"]\n",
    "        train_info = ds.info.splits[\"train\"]\n",
    "        stream_batch_size = int(STREAM_BATCH_BYTES * (train_info.num_examples / train_info.num_bytes))\n",
    "        batch_iter = iter(ds.select_columns(\"text\").batch(stream_batch_size))\n",
    "\n",
    "        if batch_limit is not None:\n",
    "            c = None\n",
    "            for i in range(batch_limit):\n",
    "                try:\n",
    "                    process_batch(path, batch_iter, i)\n",
    "                except Exception as e:\n",
    "                    c = i\n",
    "                    if e is not StopIteration:\n",
    "                        warnings.warn(f\"Caught exception in iterator: {e}\")\n",
    "                    break\n",
    "            \n",
    "            c = c or batch_limit\n",
    "\n",
    "        else:\n",
    "            c = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    process_batch(path, batch_iter, i)\n",
    "                    c += 1\n",
    "                except Exception as e:\n",
    "                    if e is not StopIteration:\n",
    "                        warnings.warn(f\"Caught exception in iterator: {e}\")\n",
    "                    break\n",
    "\n",
    "        print(f\"Processed Batches: {c}\")\n",
    "        assert c > 0, f\"Empty or error-ridden dataset: {path}\"\n",
    "\n",
    "        print(f\"\\nSaving Dataset...\")\n",
    "        base_dataset = lance.dataset(path)\n",
    "        if c > 1:\n",
    "            for i in range(1, c):\n",
    "                print(f\"Appending Batch: {i}\")\n",
    "                aux_path = \"\".join([path, f\"_batch_{i}\"])\n",
    "                aux_dataset = lance.dataset(aux_path)\n",
    "                base_dataset.insert(aux_dataset)\n",
    "                shutil.rmtree(aux_path)\n",
    "    \n",
    "        print(\"Saved Dataset\")\n",
    "\n",
    "    return base_dataset\n",
    "\n",
    "db_name = \"stackexchange_base_db_lance\"\n",
    "lance_dataset = get_lance_dataset(os.path.sep.join([os.getcwd(), \"cache\", db_name]), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_BATCH_SIZE = 2 ** 16\n",
    "\n",
    "lance_batches = lance_dataset.to_batches(batch_size=LOAD_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentenceTransformer(\"\").encode()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
